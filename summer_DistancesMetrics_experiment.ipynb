{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42538, 44)\n",
      "Index([u'loan_amnt', u'funded_amnt', u'term', u'int_rate', u'installment',\n",
      "       u'grade', u'emp_length', u'home_ownership', u'annual_inc',\n",
      "       u'verification_status', u'loan_status', u'purpose', u'title',\n",
      "       u'zip_code', u'dti', u'delinq_2yrs', u'earliest_cr_line',\n",
      "       u'inq_last_6mths', u'mths_since_last_delinq', u'mths_since_last_record',\n",
      "       u'open_acc', u'pub_rec', u'revol_bal', u'revol_util', u'total_acc',\n",
      "       u'total_pymnt', u'total_rec_prncp', u'total_rec_int',\n",
      "       u'total_rec_late_fee', u'recoveries', u'collection_recovery_fee',\n",
      "       u'last_pymnt_d', u'last_pymnt_amnt', u'last_credit_pull_d',\n",
      "       u'collections_12_mths_ex_med', u'application_type', u'acc_now_delinq',\n",
      "       u'chargeoff_within_12_mths', u'delinq_amnt', u'pub_rec_bankruptcies',\n",
      "       u'tax_liens', u'hardship_flag', u'disbursement_method',\n",
      "       u'debt_settlement_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "filename = 'C:/Users/yuwei/Downloads/lime-master/loan_dataset/selected.csv'\n",
    "#test_filename = 'C:/Users/yuwei/Downloads/lime-master/loan_dataset/av-sigmacab-test.csv'\n",
    "dataset = pd.read_csv(filename, header=0)\n",
    "cols=dataset.columns\n",
    "print (dataset.shape)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.ravel(np.array(dataset['grade'].values))\n",
    "dataset = dataset.drop(['grade'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'loan_status', 'purpose', 'title', 'zip_code', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_pymnt', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d', 'collections_12_mths_ex_med', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens', 'hardship_flag', 'disbursement_method', 'debt_settlement_flag']\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(dataset.columns)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 21, 22, 23, 29, 30, 32, 34, 40, 41, 42]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = []\n",
    "n = 0\n",
    "for i in dataset.columns:\n",
    "    if dataset[i].dtype == 'object':\n",
    "        categorical_columns.append(n)\n",
    "    n = n+1\n",
    "        \n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "for feature in categorical_columns:\n",
    "    #print(feature)\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(dataset.iloc[:,feature])\n",
    "    dataset.iloc[:,feature] = le.transform(dataset.iloc[:,feature])\n",
    "    categorical_names[feature] = le.classes_\n",
    "    #print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "imp = Imputer(missing_values='NaN',strategy='most_frequent',axis=0,verbose=0,copy=True)\n",
    "dataset = imp.fit_transform(dataset) #dataframe to array ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000L, 43L)\n",
      "(32538L, 43L)\n"
     ]
    }
   ],
   "source": [
    "trainset = dataset[:10000]\n",
    "train_target = target[:10000]\n",
    "testset = dataset[10000:]\n",
    "test_target = target[10000:]\n",
    "print(trainset.shape)\n",
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = sklearn.preprocessing.OneHotEncoder(categorical_features =  categorical_columns)\n",
    "#encoder.fit(dataset)\n",
    "#encoded_train = encoder.transform(trainset)  #more scientific but useless (the accuracy will decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(max_features = 10)\n",
    "model_dt.fit(trainset, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.686182\n"
     ]
    }
   ],
   "source": [
    "predict_result_dt = model_dt.predict(testset)\n",
    "print(\"Accuracy: %f\" % accuracy_score(test_target,predict_result_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import pydotplus \n",
    "dot_data = tree.export_graphviz(model_dt, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         class_names = ['A','B','C','D','E','F','G'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.write_pdf(\"lendingclub.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model_rf = RandomForestClassifier(n_estimators=500)\n",
    "#model_rf.fit(trainset, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_result = model_rf.predict(testset)\n",
    "#print(\"Accuracy: %f\" % accuracy_score(test_target,predict_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_fn_rf = lambda x: model_rf.predict_proba(x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(trainset ,\n",
    "                                                   feature_names = feature_names,class_names=['A','B','C','D','E','F','G'],\n",
    "                                                   categorical_features=categorical_columns, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3,verbose = True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7645;\n",
    "#print(testset[idx])\n",
    "print(test_target[idx])\n",
    "print(predict_result_dt[idx])\n",
    "exp = explainer.explain_instance(testset[idx],model_dt.predict_proba, \n",
    "                                 num_features=6, labels = [0,1,2,3,4,5,6],\n",
    "                                 distance_metric = 'cosine') #euclidean\n",
    "exp.show_in_notebook(show_all=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_dt.feature_importances_\n",
    "t1 = [(i,importances[i]) for i in range(len(importances))]\n",
    "def by_importance(t):\n",
    "    return -t[1]\n",
    "t2 = sorted(t1,key = by_importance)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldset = set([3,26,22,4,30,17,13,19,24,2])\n",
    "dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6}\n",
    "true_num = 0\n",
    "for i in range(1): #set the number of test set\n",
    "    topset = set()\n",
    "    predictlabel = predict_result_dt[i]\n",
    "    labelnum = dict[predictlabel]\n",
    "    exp = explainer.explain_instance(testset[i],model_dt.predict_proba,\n",
    "                                     num_features=3,labels = [labelnum],\n",
    "                                     distance_metric = 'euclidean')\n",
    "    for j in range(3):\n",
    "        topset.add(exp.as_map()[labelnum][j][0]) \n",
    "    if topset < goldset:\n",
    "        true_num = true_num + 1\n",
    "print(true_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
